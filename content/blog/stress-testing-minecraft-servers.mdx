---
title: Stress Testing Minecraft Servers
description: Learn how to properly stress test your Minecraft server, measure performance metrics, identify bottlenecks, and optimize for peak player loads
author: Pistonmaster
date: 2026-02-04
tags: [minecraft, stress-testing, performance, optimization, tps, mspt]
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs'
import { Callout } from 'fumadocs-ui/components/callout'

## Understanding Server Stress Testing

Stress testing simulates high player loads on your Minecraft server to find performance bottlenecks before real players hit them. The goal isn't to see when the server crashes -- it's to find out how many players you can actually handle.

A new plugin might work fine with 10 players and cause severe lag with 50. A VPS upgrade might not deliver the improvement you expected. Stress testing gives you hard numbers instead of guesses.

### Key Performance Metrics

Minecraft servers have two numbers you need to watch: TPS and MSPT.

**TPS (Ticks Per Second)** measures the server's tick rate, targeting 20 ticks per second. **MSPT (Milliseconds Per Tick)** measures how long each tick takes to process. MSPT is more revealing because it shows performance trends before TPS actually drops -- a server at 45ms MSPT is still hitting 20 TPS but has almost no headroom left.

| TPS | MSPT | Server State |
|-----|------|--------------|
| 20.0 | &lt;40ms | Healthy, has headroom |
| 18-19 | 40-50ms | Minor lag, running near limit |
| 15-17 | 50-70ms | Noticeable delays |
| &lt;15 | &gt;70ms | Severe, nearly unplayable |

The best tool for monitoring both is [Spark](https://spark.lucko.me/), which works on Paper, Spigot, Fabric, Forge, and proxies. Install it, then use these commands in-game:

```text
/spark tps              # Shows TPS, MSPT, and CPU usage
/spark profiler start   # Start CPU profiler
/spark profiler stop    # Stop and generate shareable report
/spark heapsummary      # Memory breakdown
/spark gc               # Garbage collection activity
```

Spark's profiler generates flamegraphs showing exactly where server time is spent. Look for the widest sections -- those consume the most time. Plugin names appearing disproportionately large indicate a problem worth investigating.

## Optimize Before Testing

<Callout type="warning">
Testing an unoptimized server wastes time. You'll just discover it needs optimization. Get your server running well first, then stress test to see what it can handle.
</Callout>

### Server Software

[Paper](https://papermc.io/) is the standard for performance. It includes hundreds of optimizations over Spigot while maintaining plugin compatibility. For servers expecting 100+ players, consider [Pufferfish](https://pufferfish.host/) (a Paper fork tuned for high player counts). Avoid vanilla Bukkit and CraftBukkit -- they lack modern optimizations entirely.

### View and Simulation Distance

These are the most impactful settings you'll adjust.

```properties title="server.properties"
view-distance=8
simulation-distance=4
```

Every chunk within simulation distance requires entity processing, crop growth, and redstone ticking -- far more expensive than just rendering terrain. Setting simulation distance lower than view distance gives players good visibility without the processing overhead.

| Server Type | View Distance | Simulation Distance |
|-------------|---------------|---------------------|
| Budget / high player count | 5-6 | 3-4 |
| Mid-range | 7-8 | 4-5 |
| High-performance | 10+ | 6-8 |

### Entity Limits

Mob AI is one of the most expensive operations on any Minecraft server. Tighten the defaults in `paper-world-defaults.yml`:

```yaml title="paper-world-defaults.yml"
entities:
  spawning:
    spawn-limits:
      monster: 20
      creature: 5
      water_creature: 2
      water_ambient: 2
      ambient: 1
    ticks-per-spawn:
      monster: 10
      creature: 400
      water_creature: 400
      ambient: 400
  behavior:
    max-entity-collisions: 2  # Down from 8
```

### Pregenerate Chunks

Chunk generation is extremely expensive -- TPS can drop from 20 to 2-8 while generating new terrain. Use the [Chunky](https://modrinth.com/plugin/chunky) plugin to pregenerate before players explore:

```text
/chunky world world
/chunky radius 5000
/chunky start
```

Run this overnight or on a separate server, then copy the world files to production. Never pregenerate while players are online.

### Java Flags

The right JVM flags depend on your Java version and hardware. Java 25 brought production-ready [ZGC](https://wiki.openjdk.org/display/zgc) and [Compact Object Headers (JEP 519)](https://openjdk.org/jeps/519), which together are now the recommended choice for servers with sufficient hardware. For older Java versions or smaller setups, [Aikar's G1GC flags](https://aikar.co/2018/07/02/tuning-the-jvm-g1gc-garbage-collector-flags-for-minecraft/) remain solid.

Replace the memory values with your available RAM (Xms and Xmx should match):

<Tabs>
<Tab value="zgc" label="Java 25+ (ZGC)" default>

```bash title="start-server.sh"
java -Xms10G -Xmx10G -XX:+UseZGC \
  -XX:+UseCompactObjectHeaders -XX:+AlwaysPreTouch \
  -XX:+DisableExplicitGC -XX:+PerfDisableSharedMem \
  -XX:+UseDynamicNumberOfGCThreads -jar paper.jar --nogui
```

ZGC is self-tuning — no manual GC parameters needed. Compact Object Headers reduce per-object header size from 12 to 8 bytes, lowering memory usage and GC pressure across the board.

**Requirements:** 8+ CPU cores and 6GB+ allocated RAM. On smaller hardware, use G1GC instead.

</Tab>
<Tab value="g1gc" label="Java 21 and below (Aikar's G1GC)">

```bash title="start-server.sh"
java -Xms10G -Xmx10G -XX:+UseG1GC -XX:+ParallelRefProcEnabled \
  -XX:MaxGCPauseMillis=200 -XX:+UnlockExperimentalVMOptions \
  -XX:+DisableExplicitGC -XX:+AlwaysPreTouch \
  -XX:G1NewSizePercent=30 -XX:G1MaxNewSizePercent=40 \
  -XX:G1HeapRegionSize=8M -XX:G1ReservePercent=20 \
  -XX:G1HeapWastePercent=5 -XX:G1MixedGCCountTarget=4 \
  -XX:InitiatingHeapOccupancyPercent=15 \
  -XX:G1MixedGCLiveThresholdPercent=90 \
  -XX:G1RSetUpdatingPauseTimePercent=5 \
  -XX:SurvivorRatio=32 -XX:+PerfDisableSharedMem \
  -XX:MaxTenuringThreshold=1 -jar paper.jar --nogui
```

</Tab>
</Tabs>

#### G1GC vs ZGC

**G1GC (Aikar's flags)** divides the heap into regions and collects garbage in phases, aiming for a 200ms pause time target. It still produces stop-the-world pauses that scale with heap size, but Aikar's tuning parameters optimize it for Minecraft's allocation patterns — lots of short-lived objects from chunk loading, entity processing, and packet handling. Works well on modest hardware and smaller heaps.

**ZGC** does nearly all garbage collection concurrently with the application. Pause times stay under 1ms regardless of heap size, which eliminates those random TPS drops and rubber-banding caused by GC pauses. It's self-tuning and needs almost no configuration, but trades CPU cycles for those low pause times.

**Compact Object Headers** ([JEP 519](https://openjdk.org/jeps/519)) complement either collector. They shrink object headers from 12 bytes to 8 bytes, reducing heap usage and improving cache locality. Minecraft creates millions of small, short-lived objects per tick, so the savings add up — benchmarks show up to 22% less heap usage.

**In practice:** If your server has 8+ cores and you're running Java 25, use ZGC — the sub-millisecond pauses mean GC is effectively invisible to players. If you're on older Java, constrained hardware (under 8 cores), or allocating less than 6GB RAM, stick with Aikar's G1GC flags. Monitor with `/spark gc` either way.

For deeper benchmarks and analysis, see [brucethemoose's Minecraft Performance Flags Benchmarks](https://github.com/brucethemoose/Minecraft-Performance-Flags-Benchmarks) and [Obydux's modern startup flags](https://github.com/Obydux/Minecraft-startup-flags).

## Conducting the Stress Test

The key is testing incrementally -- connecting 500 bots at once teaches you nothing except "it crashes."

### Phase 1: Baseline

Start with an empty server. Record idle TPS (should be 20.0), MSPT (should be under 10ms), memory usage, and CPU. This is your reference point.

### Phase 2: Gradual Load

Increase bots in steps and hold each level for 10-15 minutes:

| Step | Bots | Goal |
|------|------|------|
| 1 | 10 | Verify test setup works |
| 2 | 25 | Watch for early degradation |
| 3 | 50 | Typical peak for small servers |
| 4 | 100 | Mid-size server stress test |
| 5 | 200+ | Find the breaking point |

At each step, record TPS, MSPT (current, median, and 95th percentile), memory trends, and any errors. Run a Spark profiler for 2 minutes during each level to capture where time is being spent.

### Phase 3: Realistic Behavior

Idle bots standing still don't represent real players. Add movement and actions to actually hit the parts that slow down:

<Tabs>
<Tab value="movement" label="Movement" default>

Tests entity tracking, pathfinding, collision detection, and chunk loading. Random walking is enough to stress entity tracking and collision — check EntityAI CPU usage and chunk loading frequency in Spark.

</Tab>
<Tab value="exploration" label="Exploration">

Tests world I/O and chunk generation. Bots flying or moving to unexplored areas reveal whether your pregeneration was sufficient. Watch for disk I/O spikes and TPS drops.

</Tab>
<Tab value="combat" label="Combat">

Tests mob AI, damage calculations, and entity death/spawn cycles. High entity AI usage and frequent state changes stress the server differently than passive movement.

</Tab>
</Tabs>

### Phase 4: Spike Testing

Real servers experience sudden load spikes -- 100 players joining within 30 seconds during an event. Start with 10 bots connected, then join 50 simultaneously. Watch whether TPS drops below 15 during the surge and how long recovery takes.

### Phase 5: Endurance

Some issues only appear after hours: memory leaks, gradual resource exhaustion, increasing GC pause times. Connect 50-75% of your target capacity and let it run for 4-8 hours. Climbing memory usage or increasing MSPT over time signals a problem.

## Identifying Bottlenecks

**TPS drops proportionally with player count**: General overhead from entities, chunks, and networking. Reduce view/simulation distance and entity caps.

**Random TPS spikes**: Usually chunk generation, large redstone devices, or plugin tasks running on the main thread. Pregenerate more world and profile during the spikes to identify the cause.

**MSPT creeping up over time**: Memory pressure or resource exhaustion. Check Spark's heap summary for unusual object counts or steadily growing memory usage.

**Good TPS but high CPU (&gt;80%)**: You're close to the limit with no headroom for spikes. Optimize further or upgrade hardware.

When Spark shows a specific plugin consuming more than 10% of CPU, investigate its configuration first -- many plugins have expensive features that can be disabled. If entity AI dominates the profile (&gt;30%), lower mob caps. If chunk operations are excessive, tighten chunk loading rates in `paper-global.yml`.

## Using SoulFire for Testing

I'd recommend [SoulFire](/download) for this. Unlike most bot frameworks that reimplement the Minecraft protocol from scratch, SoulFire runs actual Fabric client code -- so bots behave exactly like real players at the protocol level. You don't get weird packet timing or broken physics that throws off your results. The load is basically identical to real players, which is the whole point.

It also supports multiple Minecraft versions through ViaFabricPlus, so you can test whatever version you're running without hunting for a compatible tool.

**Here's how I usually run a test:**

1. Set your target server and bot count in the SoulFire interface
2. Stagger the joins (1-3 seconds between bots) so you don't flood the login server
3. Turn on the movement and activity plugins so bots aren't just standing there
4. Keep Spark running on the server the whole time
5. Hold each load level for 15-30 minutes before bumping it up

## When to Test

Don't just test once. Run tests before launches, after major plugin updates, before events with expected high turnout, and after hardware changes. A monthly baseline test catches gradual degradation from accumulating data and slow memory leaks that daily monitoring misses.

The process is simple: optimize first, monitor with Spark, test incrementally with realistic behavior, fix what the profiles reveal, and retest. Do this before your players do it for you.
